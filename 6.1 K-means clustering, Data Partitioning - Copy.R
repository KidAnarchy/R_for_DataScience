#---------------------------------------------------------
#               Data Clustering
#---------------------------------------------------------
# 1. Data Partitioningจะเป็นการแบ่งกลุ่ม โดยที่ระยะห่างของวัตถุภายในกลุ่มเดียวกัน อยู่ใกล้กันมากที่สุดขั้นตอนวิธีที่นิยมใช้ คือ K-means
# 2. การแบ่งกลุ่มแบบลำดับขั้นหรือว่า Hierarchical Clusteringจะเป็นการสร้างโครงสร้างจากข้อมูลเป็นลำดับขั้น ซึ่งมีลักษณะคล้ายแผนภาพต้นไม้
# โดยใช้เมตริกซ์ระยะทางขั้นตอนวิธีที่นิยมใช้ในการวิเคราห์แบ่งกลุ่มแบบลำดับขั้นก็คือ Agglomerative และ Divisive

# K-Means จะมี Argumentที่เราสามารถกำหนดค่าได้ดังนี้
# 1. X เป็นเมทริกซ์ของชุดข้อมูลที่เป็นตัวเลข
# 2. Center เป็นจำนวนกลุ่มที่ต้องการหรือว่าค่า K นั่นเองค่ะ
# 3. iter.max เป็นจำนวนรอบสูงสุดที่ต้องให้อัลกอริทึมทำงาน
# 4. nstart เป็นการกำหนดตัวเลขที่ต้องการให้สุ่มตัวอย่างจุดศูนย์กลางเป็นตัวแทนของแต่ละกลุ่ม หลายครั้งและเลือกกลุ่มของจุดศูนย์กลางที่ดีที่สุดในการแบ่งกลุ่ม โดยค่าเริ่มต้นก็คือ 1
# 5. algorithm เป็นชื่อย่อของ algorithm ที่ใช้ในการจัดกลุ่มโดยวิธี K-Means ซึ่งค่าเริ่มต้นก็คือ Hartigan-Wong
# 6. Trace ใช้เฉพาะกรณีที่เลือกDefault Algorithm เป็น Hardigan-Wongถ้าเป็น True จะแสดงความคืบหน้าของการทำงานของ Algorithm

# Online Shopping
data <- data.frame(
  age = c(22,22,23,24,48,27,28,32,34,35,38,40,55,60,50,53,40),
  online_shopping = c(15,20,30,18,25,25,30,50,65,55,68,50,20,15,35,32,40)
)

# K-means clustering
(kc <- kmeans(data, 3, algorithm = "MacQueen"))
# สำหรับค่าของผลบวกกำลัง 2ของ Distance ตรงนี้ถ้าค่ายิ่งน้อยแปลว่ามีการเกาะกลุ่มกันของวัตถุใน Cluster มาก
# ส่วนค่า between sum squaresหารด้วยค่า total sum square ตรงนี้ถ้ามีค่ายิ่งมากก็จะแปลว่าการแบ่งกลุ่มทำให้เราเห็นรูปแบบของแต่ละ Cluster ได้ชัดเจน
# Available components: คือค่า kC เราสามารถดูได้โดย kc$ แล้วก็ชื่อของ Component เช่น kc$withinss

#plot graph
plot(data, col=kc$cluster)
# Show centroid
points(kc$centers,col=1:3, pch=18, cex=2)

#-----------------------------------------------------